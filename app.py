import streamlit as st
import pandas as pd
import json
import warnings
import os
import time
import re
import jieba
import pickle
from google import genai
from google.genai import types

# å¿½ç•¥æ— å…³è­¦å‘Š
warnings.filterwarnings('ignore')

# ================= 1. åŸºç¡€é…ç½® =================

st.set_page_config(
    page_title="ChatMDM - æ™ºèƒ½ä¸»æ•°æ®å¯¹é½", 
    layout="wide", 
    initial_sidebar_state="expanded"
)

# --- æ¨¡å‹é…ç½® ---
MODEL_NAME = "gemini-2.0-flash" 

# --- å…¨å±€å¸¸é‡ ---
MASTER_COL_NAME = "åŒ»é™¢åç§°"
MASTER_COL_CODE = "åŒ»é™¢ç¼–ç "
MASTER_COL_PROV = "çœä»½"
MASTER_COL_CITY = "åŸå¸‚"
CACHE_FILE = "mdm_cache.pkl"  # æœ¬åœ°ç¼“å­˜æ–‡ä»¶è·¯å¾„

try:
    FIXED_API_KEY = st.secrets.get("GENAI_API_KEY", os.getenv("GENAI_API_KEY", ""))
except:
    FIXED_API_KEY = "" 

# ================= 2. è§†è§‰ä½“ç³» =================

def inject_custom_css():
    st.markdown("""
        <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');
        
        .stApp {
            background-color: #050505;
            background-image: radial-gradient(circle at 50% 0%, #1a1a2e 0%, #050505 40%);
            font-family: 'Inter', "Microsoft YaHei", sans-serif;
        }
        
        .glass-card {
            background: rgba(255, 255, 255, 0.03);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.08);
            border-radius: 12px;
            padding: 20px;
            margin-bottom: 20px;
        }
        
        .metric-label { font-size: 12px; color: #94a3b8; text-transform: uppercase; letter-spacing: 1px; }
        .metric-value { font-size: 28px; font-weight: 700; color: #ffffff; }
        .metric-sub { font-size: 12px; color: #64748b; margin-top: 4px; }
        
        [data-testid="stSidebar"] { background-color: #000000 !important; border-right: 1px solid #222; }
        [data-testid="stDataFrame"] { border: 1px solid #333; border-radius: 8px; }
        .stProgress > div > div > div > div { background-color: #3b82f6; }
        </style>
    """, unsafe_allow_html=True)

def render_metric_card(label, value, sub_text=""):
    st.markdown(f"""
    <div class="glass-card">
        <div class="metric-label">{label}</div>
        <div class="metric-value">{value}</div>
        <div class="metric-sub">{sub_text}</div>
    </div>
    """, unsafe_allow_html=True)

# ================= 3. NLP & æ•°æ®å¤„ç†å·¥å…· =================

STOP_WORDS = {
    "åŒ»é™¢", "æœ‰é™å…¬å¸", "æœ‰é™", "è´£ä»»", "å…¬å¸", "åˆ†é™¢", "é™„å±", 
    "å­¦", "æ ¡", "å«ç”Ÿ", "æœåŠ¡", "ä¸­å¿ƒ", "ç«™", "æ‰€", "é—¨è¯Š", "éƒ¨",
    "çœ", "å¸‚", "åŒº", "å¿", "è¡—é“", "ç¤¾åŒº"
}

def extract_core_tokens(text):
    if not isinstance(text, str): return set()
    text = re.sub(r'[ï¼ˆ(].*?[)ï¼‰]', '', text)
    words = jieba.lcut_for_search(text)
    tokens = set()
    for w in words:
        w = w.strip()
        if w not in STOP_WORDS and len(w) > 1:
            tokens.add(w)
    return tokens

@st.cache_resource
def get_client():
    if not FIXED_API_KEY: return None
    return genai.Client(api_key=FIXED_API_KEY, http_options={'api_version': 'v1beta'})

# --- ç¼“å­˜ç®¡ç†å‡½æ•° ---

def load_cached_master():
    """å°è¯•ä»æœ¬åœ°åŠ è½½å·²å¤„ç†å¥½çš„ Pickle æ–‡ä»¶"""
    if os.path.exists(CACHE_FILE):
        try:
            df = pd.read_pickle(CACHE_FILE)
            return df
        except Exception as e:
            return None
    return None

def save_master_cache(df):
    """å°†å¤„ç†å¥½çš„ DataFrame (å« Tokens) ä¿å­˜åˆ°æœ¬åœ°"""
    try:
        df.to_pickle(CACHE_FILE)
    except Exception as e:
        st.error(f"ç¼“å­˜å†™å…¥å¤±è´¥: {e}")

def clear_master_cache():
    """æ¸…é™¤æœ¬åœ°ç¼“å­˜"""
    if os.path.exists(CACHE_FILE):
        os.remove(CACHE_FILE)

# --- æ•°æ®åŠ è½½ ---

def process_master_data(uploaded_file):
    """
    å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶ï¼šè¯»å– -> æ¸…æ´— -> åˆ†è¯
    æ³¨æ„ï¼šè¿™é‡Œä¸å†ä½¿ç”¨ @st.cache_dataï¼Œå› ä¸ºæˆ‘ä»¬ç”¨æœ¬åœ°æ–‡ä»¶æŒä¹…åŒ–æ›¿ä»£äº†å†…å­˜ç¼“å­˜
    """
    try:
        if uploaded_file.name.endswith('.xlsx'): 
            df = pd.read_excel(uploaded_file, engine='openpyxl')
        else: 
            df = pd.read_csv(uploaded_file)
        
        df = df.astype(str)
        df.columns = df.columns.str.strip()
        
        for col in df.columns:
            df[col] = df[col].apply(lambda x: x.strip().replace('nan', '') if x != 'nan' else '')

        col_map_rename = {}
        for col in df.columns:
            if "åç§°" in col and "åŒ»é™¢" in col: col_map_rename[col] = MASTER_COL_NAME
            elif "ç¼–ç " in col: col_map_rename[col] = MASTER_COL_CODE
            elif "çœ" in col: col_map_rename[col] = MASTER_COL_PROV
            elif "å¸‚" in col: col_map_rename[col] = MASTER_COL_CITY
        
        if col_map_rename:
            df = df.rename(columns=col_map_rename)

        required = [MASTER_COL_NAME, MASTER_COL_CODE]
        if not all(col in df.columns for col in required):
            return None, f"ç¼ºå°‘å¿…è¦åˆ—: {required}"
        
        # æ„å»ºç´¢å¼•
        with st.spinner("æ­£åœ¨æ„å»ºæœç´¢å¼•æ“ç´¢å¼•..."):
            df['tokens'] = df[MASTER_COL_NAME].apply(extract_core_tokens)
            
        return df, "SUCCESS"

    except Exception as e:
        return None, f"è¯»å–å¤±è´¥: {str(e)}"

def clean_json_response(text):
    text = text.replace("```json", "").replace("```", "").strip()
    try:
        return json.loads(text)
    except:
        return None

# ================= 4. å¬å›ä¸åŒ¹é…é€»è¾‘ =================

def get_candidates_by_keywords(df_master, target_name, top_k=15):
    target_tokens = extract_core_tokens(str(target_name))
    if not target_tokens: return pd.DataFrame()

    def calc_score(master_tokens):
        if not master_tokens: return 0.0
        intersection = len(target_tokens & master_tokens)
        union = len(target_tokens | master_tokens)
        if union == 0: return 0.0
        return intersection / union

    scores = df_master['tokens'].apply(calc_score)
    valid_mask = scores > 0.25 
    if not valid_mask.any(): return pd.DataFrame()
        
    candidates = df_master.loc[valid_mask].copy()
    candidates['sim_score'] = scores[valid_mask]
    
    candidates = candidates.sort_values('sim_score', ascending=False).head(top_k)
    candidates['__source__'] = 'å…³é”®è¯å¬å›(å¼‚åœ°/æ¨¡ç³Š)'
    return candidates

def get_candidates_smart(df_master, mapping, target_name, target_prov, target_city):
    candidates_list = []
    
    # ç­–ç•¥ A: åŒåŸ
    if target_city and target_city != "nan":
        df_geo = df_master[df_master[MASTER_COL_CITY] == target_city].copy()
        if not df_geo.empty:
            df_geo['__source__'] = 'åŒåŸèŒƒå›´'
            candidates_list.append(df_geo.head(30))

    # ç­–ç•¥ B: å…³é”®è¯
    if len(str(target_name)) >= 2:
        df_keyword = get_candidates_by_keywords(df_master, target_name, top_k=15)
        if not df_keyword.empty:
            candidates_list.append(df_keyword)

    if not candidates_list: return pd.DataFrame()
    
    final = pd.concat(candidates_list)
    final = final.drop_duplicates(subset=[MASTER_COL_CODE])
    return final

def call_ai_matching(client, target_name, target_prov, target_city, candidates_df):
    candidate_list_str = ""
    candidate_map = {} 
    
    for idx, row in candidates_df.iterrows():
        key = str(idx) 
        source_tag = row.get('__source__', 'æœªçŸ¥')
        info = f"ID:{key} | åç§°:{row[MASTER_COL_NAME]} | åŒºåŸŸ:{row[MASTER_COL_PROV]}-{row[MASTER_COL_CITY]} | æ¥æº:[{source_tag}]"
        candidate_list_str += info + "\n"
        candidate_map[key] = row
        
    if not candidate_list_str: return None 

    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªåŒ»ç–—ä¸»æ•°æ®å¯¹é½ä¸“å®¶ã€‚
    ã€ä»»åŠ¡ç›®æ ‡ã€‘åˆ¤æ–­ã€å¾…æ¸…æ´—æ•°æ®ã€‘æ˜¯å¦å¯¹åº”åˆ—è¡¨ä¸­çš„æŸå®¶æ ‡å‡†æœºæ„ã€‚
    
    ã€å¾…æ¸…æ´—æ•°æ®ã€‘
    åç§°: {target_name}
    ä½ç½®: {target_prov} - {target_city}
    
    ã€å€™é€‰åˆ—è¡¨ã€‘(æ³¨æ„æ¥æºæ ‡ç­¾)
    {candidate_list_str}
    
    ã€æ ¸å¿ƒæ¨ç†é€»è¾‘ã€‘
    1. **è¯†åˆ«æœ‰æ•ˆä¿¡æ¯**ï¼šå¾…æ¸…æ´—æ•°æ®çš„ã€åŸå¸‚ã€‘å¯èƒ½å¡«é”™ï¼Œä½†ã€åç§°ã€‘ä¸­çš„ä¸“æœ‰åè¯ï¼ˆå¦‚"åå’Œ"ã€"åè¥¿"ã€"çœç«‹"ï¼‰é€šå¸¸æ˜¯å‡†ç¡®çš„ã€‚
    2. **ä¼˜å…ˆçº§åˆ¤å®š**ï¼š
       - **Case A (åŸå¸‚é”™è¯¯ä¿®æ­£)**ï¼šå¦‚æœ `æ¥æº:[å…³é”®è¯å¬å›]` ä¸­æœ‰åç§°**é«˜åº¦ä¸€è‡´**ï¼ˆåŒ…å«ç›¸åŒçš„æ ¸å¿ƒç‰¹æŒ‡è¯ï¼‰çš„æœºæ„ï¼Œå³ä½¿åŸå¸‚ä¸ç¬¦ï¼Œä¹Ÿåº”åˆ¤å®šä¸ºåŒ¹é…ã€‚
       - **Case B (åŒåŸå¸¸è§„åŒ¹é…)**ï¼šåœ¨ `æ¥æº:[åŒåŸèŒƒå›´]` ä¸­å¯»æ‰¾åç§°å«ä¹‰ä¸€è‡´çš„æœºæ„ã€‚
    3. **ç±»å‹ä¸€è‡´æ€§æ ¡éªŒ**ï¼šä¸¥ç¦å°†"å«ç”Ÿå®¤"åŒ¹é…åˆ°"ç»¼åˆåŒ»é™¢"ã€‚
    4. **æ— æ³•ç¡®å®š**ï¼šè¿”å› nullã€‚
    
    ã€è¾“å‡º JSON æ ¼å¼ã€‘
    {{
        "matched_id": "å€™é€‰ID (String) æˆ– null",
        "confidence": 0.0-1.0,
        "reason": "ç®€è¿°ç†ç”±"
    }}
    """
    
    try:
        response = client.models.generate_content(
            model=MODEL_NAME, 
            contents=prompt,
            config=types.GenerateContentConfig(response_mime_type="application/json")
        )
        result = clean_json_response(response.text)
        
        if result and result.get('matched_id'):
            matched_id = str(result['matched_id'])
            if matched_id in candidate_map:
                matched_row = candidate_map[matched_id]
                return {
                    "æ ‡å‡†ç¼–ç ": matched_row[MASTER_COL_CODE],
                    "æ ‡å‡†åç§°": matched_row[MASTER_COL_NAME],
                    "æ ‡å‡†çœä»½": matched_row[MASTER_COL_PROV],
                    "æ ‡å‡†åŸå¸‚": matched_row[MASTER_COL_CITY],
                    "ç½®ä¿¡åº¦": result.get('confidence', 0.5),
                    "åŒ¹é…åŸå› ": result.get('reason', 'AIæ¨ç†'),
                    "åŒ¹é…çŠ¶æ€": "AIåŒ¹é…"
                }
        return {"åŒ¹é…åŸå› ": result.get('reason', 'æœªåœ¨å€™é€‰ä¸­æ‰¾åˆ°') if result else "AIè¿”å›æ ¼å¼æ— æ•ˆ", "åŒ¹é…çŠ¶æ€": "AIæœªåŒ¹é…"}
            
    except Exception as e:
        return {"åŒ¹é…åŸå› ": f"APIå¼‚å¸¸: {str(e)}", "åŒ¹é…çŠ¶æ€": "é”™è¯¯"}

# ================= 5. åˆå§‹åŒ–ä¸ä¾§è¾¹æ é€»è¾‘ (ä¿®æ”¹é‡ç‚¹) =================

inject_custom_css()
client = get_client()

# åˆå§‹åŒ– Session State
if "df_result" not in st.session_state: st.session_state.df_result = None
if "mapping_confirmed" not in st.session_state: st.session_state.mapping_confirmed = False
if "processing" not in st.session_state: st.session_state.processing = False
if "stop_signal" not in st.session_state: st.session_state.stop_signal = False
if "col_map" not in st.session_state: st.session_state.col_map = {}
# åˆå§‹åŒ– Master Data (å°è¯•ä»ç¼“å­˜åŠ è½½)
if "df_master" not in st.session_state: 
    st.session_state.df_master = load_cached_master()

with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/3063/3063823.png", width=60)
    st.title("ChatMDM")
    st.caption("Auto-Cache Edition")
    st.markdown("---")

    st.markdown("### 1ï¸âƒ£ æ ‡å‡†åº“ç®¡ç†")
    
    # é€»è¾‘åˆ†æ”¯ï¼šæœ‰ç¼“å­˜ vs æ— ç¼“å­˜
    if st.session_state.df_master is not None:
        st.success(f"âœ… å·²åŠ è½½ç¼“å­˜æ ‡å‡†åº“\n\næ•°æ®é‡: {len(st.session_state.df_master):,} æ¡")
        
        if st.button("ğŸ—‘ï¸ åˆ é™¤ç¼“å­˜ / æ›´æ¢æ–‡ä»¶"):
            clear_master_cache()
            st.session_state.df_master = None
            st.rerun()
    else:
        st.info("é¦–æ¬¡è¿è¡Œè¯·ä¸Šä¼  mdm.xlsx")
        master_file = st.file_uploader("ä¸Šä¼ æ–‡ä»¶ (è‡ªåŠ¨å»ºç«‹ç´¢å¼•ç¼“å­˜)", type=["xlsx", "csv"], key="master_uploader")

        if master_file:
            df_processed, msg = process_master_data(master_file)
            if df_processed is not None:
                st.session_state.df_master = df_processed
                # ä¿å­˜åˆ°æœ¬åœ°ç¼“å­˜
                save_master_cache(df_processed)
                st.success("ç´¢å¼•æ„å»ºå®Œæˆå¹¶å·²ç¼“å­˜ï¼")
                time.sleep(1)
                st.rerun()
            else:
                st.error(msg)

    st.markdown("---")
    
    # é‡ç½®ä»»åŠ¡æŒ‰é’® (åªæ¸…ç©ºå¾…å¤„ç†æ•°æ®ï¼Œä¸åˆ ä¸»æ•°æ®)
    if st.button("ğŸ”„ é‡ç½®ä»»åŠ¡ (ä¿ç•™æ ‡å‡†åº“)", use_container_width=True):
        # æ¸…é™¤æ‰€æœ‰ session stateï¼Œé™¤äº† df_master
        saved_master = st.session_state.df_master
        st.session_state.clear()
        st.session_state.df_master = saved_master
        st.rerun()
        
    if st.session_state.df_result is not None:
        st.divider()
        st.markdown("### ğŸ“¥ ç»“æœå¯¼å‡º")
        df_exp = st.session_state.df_result
        done_cnt = len(df_exp[df_exp['åŒ¹é…çŠ¶æ€'] != 'å¾…å¤„ç†'])
        match_cnt = len(df_exp[df_exp['æ ‡å‡†ç¼–ç '].notna()])
        st.caption(f"è¿›åº¦: {done_cnt}/{len(df_exp)} | å‘½ä¸­: {match_cnt}")
        csv = df_exp.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ä¸‹è½½ç»“æœ", data=csv, file_name="mdm_result.csv", mime="text/csv", type="primary")

# ================= 6. ä¸»é€»è¾‘ =================

st.title("ğŸ¥ åŒ»ç–—ä¸»æ•°æ®æ™ºèƒ½å¯¹é½ç³»ç»Ÿ")

if not FIXED_API_KEY:
    st.warning("âš ï¸ è¯·é…ç½® GENAI_API_KEY")

# æ£€æŸ¥ Master Data æ˜¯å¦å°±ç»ª
if st.session_state.df_master is None:
    st.info("ğŸ‘‹ æ¬¢è¿ï¼è¯·ä»å·¦ä¾§ä¸Šä¼ æ ‡å‡†åº“ä»¥å¼€å§‹ã€‚ç³»ç»Ÿä¼šè‡ªåŠ¨ç¼“å­˜æ–‡ä»¶ï¼Œåç»­æ— éœ€é‡å¤ä¸Šä¼ ã€‚")
    st.stop()
else:
    df_master = st.session_state.df_master # å¼•ç”¨èµ‹å€¼

# --- Phase 1: ä¸Šä¼  ---
if st.session_state.df_result is None:
    st.markdown("### 2ï¸âƒ£ ä¸Šä¼ å¾…æ¸…æ´—æ•°æ®")
    uploaded_file = st.file_uploader("æ”¯æŒ Excel / CSV", type=["xlsx", "csv"], key="target_uploader")
    
    if uploaded_file:
        try:
            if uploaded_file.name.endswith('.csv'): df_temp = pd.read_csv(uploaded_file)
            else: df_temp = pd.read_excel(uploaded_file, engine='openpyxl')
            
            df_temp = df_temp.astype(str)
            for col in ['åŒ¹é…çŠ¶æ€', 'æ ‡å‡†ç¼–ç ', 'æ ‡å‡†åç§°', 'æ ‡å‡†çœä»½', 'æ ‡å‡†åŸå¸‚', 'åŒ¹é…åŸå› ']:
                df_temp[col] = None
            df_temp['åŒ¹é…çŠ¶æ€'] = 'å¾…å¤„ç†'
            df_temp['ç½®ä¿¡åº¦'] = 0.0
            
            st.session_state.df_result = df_temp
            st.rerun()
        except Exception as e:
            st.error(f"è¯»å–å¤±è´¥: {e}")

# --- Phase 2: æ˜ å°„ ---
elif not st.session_state.mapping_confirmed:
    st.markdown("### 3ï¸âƒ£ å­—æ®µæ˜ å°„")
    df_cols = st.session_state.df_result.columns.tolist()
    c1, c2, c3 = st.columns(3)
    with c1: t_name = st.selectbox("ã€åç§°ã€‘åˆ—", df_cols)
    with c2: t_prov = st.selectbox("ã€çœä»½ã€‘åˆ— (å¯é€‰)", ["æ— "] + df_cols)
    with c3: t_city = st.selectbox("ã€åŸå¸‚ã€‘åˆ— (å¯é€‰)", ["æ— "] + df_cols)

    if st.button("å¼€å§‹å¤„ç†", type="primary"):
        st.session_state.col_map = {"target_name": t_name, "target_province": t_prov, "target_city": t_city}
        st.session_state.mapping_confirmed = True
        st.rerun()

# --- Phase 3: æ§åˆ¶å° ---
else:
    df_curr = st.session_state.df_result
    col_map = st.session_state.col_map
    
    total = len(df_curr)
    done_cnt = len(df_curr[df_curr['åŒ¹é…çŠ¶æ€'] != 'å¾…å¤„ç†'])
    
    c1, c2, c3, c4 = st.columns(4)
    with c1: render_metric_card("è¿›åº¦", f"{done_cnt}/{total}")
    with c2: render_metric_card("å…¨å­—åŒ¹é…", len(df_curr[df_curr['åŒ¹é…çŠ¶æ€'] == 'å…¨å­—åŒ¹é…']))
    with c3: render_metric_card("AI åŒ¹é…", len(df_curr[df_curr['åŒ¹é…çŠ¶æ€'] == 'AIåŒ¹é…']))
    with c4: render_metric_card("æœªåŒ¹é…", len(df_curr[df_curr['åŒ¹é…çŠ¶æ€'] == 'AIæœªåŒ¹é…']))
    
    st.divider()
    
    col_ctrl, col_status = st.columns([1, 3])
    with col_ctrl:
        if st.button("âš¡ ç²¾ç¡®åŒ¹é… (Hash)", use_container_width=True, disabled=st.session_state.processing):
            with st.spinner("Hash æ¯”å¯¹ä¸­..."):
                t_name = col_map['target_name']
                master_dict = {str(k).strip(): v for k, v in df_master.drop_duplicates(subset=[MASTER_COL_NAME]).set_index(MASTER_COL_NAME).to_dict('index').items()}
                
                for idx, row in df_curr.iterrows():
                    if row['åŒ¹é…çŠ¶æ€'] != 'å¾…å¤„ç†': continue
                    val = str(row[t_name]).strip()
                    if val in master_dict:
                        match = master_dict[val]
                        df_curr.at[idx, 'æ ‡å‡†ç¼–ç '] = match.get(MASTER_COL_CODE)
                        df_curr.at[idx, 'æ ‡å‡†åç§°'] = val
                        df_curr.at[idx, 'æ ‡å‡†çœä»½'] = match.get(MASTER_COL_PROV)
                        df_curr.at[idx, 'æ ‡å‡†åŸå¸‚'] = match.get(MASTER_COL_CITY)
                        df_curr.at[idx, 'åŒ¹é…çŠ¶æ€'] = 'å…¨å­—åŒ¹é…'
                        df_curr.at[idx, 'ç½®ä¿¡åº¦'] = 1.0
                st.session_state.df_result = df_curr
                st.rerun()

        if not st.session_state.processing:
            if st.button("ğŸ§  AI æ·±åº¦åŒ¹é…", type="primary", use_container_width=True):
                st.session_state.processing = True
                st.session_state.stop_signal = False
                st.rerun()
        else:
            if st.button("ğŸ›‘ æš‚åœ", type="secondary", use_container_width=True):
                st.session_state.stop_signal = True
                st.session_state.processing = False
                st.rerun()

    with col_status:
        progress_bar = st.progress(0)
        status_text = st.empty()
        table_placeholder = st.empty()
        
        table_placeholder.dataframe(
            df_curr, 
            use_container_width=True, 
            column_order=['åŒ¹é…çŠ¶æ€', 'ç½®ä¿¡åº¦', 'åŒ¹é…åŸå› ', col_map['target_name'], 'æ ‡å‡†åç§°'],
            height=300
        )
        
        if st.session_state.processing:
            pending_indices = df_curr[df_curr['åŒ¹é…çŠ¶æ€'] == 'å¾…å¤„ç†'].index.tolist()
            
            if not pending_indices:
                st.session_state.processing = False
                st.success("å…¨éƒ¨å®Œæˆ")
                st.rerun()
            
            for i, idx in enumerate(pending_indices):
                if st.session_state.stop_signal:
                    st.session_state.processing = False
                    st.warning("å·²æš‚åœ")
                    st.rerun()
                    break
                
                row = df_curr.loc[idx]
                t_n = str(row[col_map['target_name']])
                t_p = str(row[col_map['target_province']]) if col_map['target_province'] != "æ— " else ""
                t_c = str(row[col_map['target_city']]) if col_map['target_city'] != "æ— " else ""
                
                status_text.text(f"æ­£åœ¨å¤„ç†: {t_n}")
                progress_bar.progress((i + 1) / len(pending_indices))
                
                candidates = get_candidates_smart(df_master, col_map, t_n, t_p, t_c)
                
                if len(candidates) > 0:
                    ai_res = call_ai_matching(client, t_n, t_p, t_c, candidates)
                    for k, v in ai_res.items():
                        if k in df_curr.columns: df_curr.at[idx, k] = v
                else:
                    df_curr.at[idx, 'åŒ¹é…çŠ¶æ€'] = 'æ— å€™é€‰'
                    df_curr.at[idx, 'åŒ¹é…åŸå› '] = 'åŒåŸ/å…³é”®è¯å‡æœªå¬å›è¿‘ä¼¼æ•°æ®'

                if i % 3 == 0:
                    st.session_state.df_result = df_curr
                    table_placeholder.dataframe(
                        df_curr, 
                        use_container_width=True, 
                        column_order=['åŒ¹é…çŠ¶æ€', 'ç½®ä¿¡åº¦', 'åŒ¹é…åŸå› ', col_map['target_name'], 'æ ‡å‡†åç§°'],
                        height=300
                    )
            
            st.session_state.df_result = df_curr
            st.session_state.processing = False
            st.success("é˜Ÿåˆ—å¤„ç†å®Œæ¯•")
            st.rerun()
