import streamlit as st
import pandas as pd
import json
import warnings
import os
import time
import re
import jieba
from google import genai
from google.genai import types

# å¿½ç•¥æ— å…³è­¦å‘Š
warnings.filterwarnings('ignore')

# ================= 1. åŸºç¡€é…ç½® =================

st.set_page_config(
    page_title="ChatMDM - æ™ºèƒ½ä¸»æ•°æ®å¯¹é½", 
    layout="wide", 
    initial_sidebar_state="expanded"
)

# --- æ¨¡å‹é…ç½® ---
MODEL_NAME = "gemini-3-pro-preview" # æ¨è Flash (é€Ÿåº¦å¿«) æˆ– Pro

# --- ä¸»æ•°æ®æ ‡å‡†åˆ—å®šä¹‰ (å›ºå®š) ---
MASTER_COL_NAME = "åŒ»é™¢åç§°"
MASTER_COL_CODE = "åŒ»é™¢ç¼–ç "
MASTER_COL_PROV = "çœä»½"
MASTER_COL_CITY = "åŸå¸‚"

try:
    # ä¼˜å…ˆä» Streamlit Secrets è·å–ï¼Œå¦‚æœæ²¡æœ‰åˆ™å°è¯•ç¯å¢ƒå˜é‡ï¼Œæœ€åç•™ç©º
    FIXED_API_KEY = st.secrets.get("GENAI_API_KEY", os.getenv("GENAI_API_KEY", ""))
except:
    FIXED_API_KEY = "" 

# ================= 2. è§†è§‰ä½“ç³» (é»‘é‡‘/ç»ç’ƒæ‹Ÿæ€) =================

def inject_custom_css():
    st.markdown("""
        <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');
        
        .stApp {
            background-color: #050505;
            background-image: radial-gradient(circle at 50% 0%, #1a1a2e 0%, #050505 40%);
            font-family: 'Inter', "Microsoft YaHei", sans-serif;
        }
        
        /* ç»ç’ƒæ‹Ÿæ€å¡ç‰‡ */
        .glass-card {
            background: rgba(255, 255, 255, 0.03);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.08);
            border-radius: 12px;
            padding: 20px;
            margin-bottom: 20px;
        }
        
        /* æŒ‡æ ‡æ ·å¼ */
        .metric-label { font-size: 12px; color: #94a3b8; text-transform: uppercase; letter-spacing: 1px; }
        .metric-value { font-size: 28px; font-weight: 700; color: #ffffff; }
        .metric-sub { font-size: 12px; color: #64748b; margin-top: 4px; }
        
        /* ä¾§è¾¹æ ä¸è¡¨æ ¼ */
        [data-testid="stSidebar"] { background-color: #000000 !important; border-right: 1px solid #222; }
        [data-testid="stDataFrame"] { border: 1px solid #333; border-radius: 8px; }
        
        /* è¿›åº¦æ¡é¢œè‰² */
        .stProgress > div > div > div > div { background-color: #3b82f6; }
        </style>
    """, unsafe_allow_html=True)

def render_metric_card(label, value, sub_text=""):
    st.markdown(f"""
    <div class="glass-card">
        <div class="metric-label">{label}</div>
        <div class="metric-value">{value}</div>
        <div class="metric-sub">{sub_text}</div>
    </div>
    """, unsafe_allow_html=True)

# ================= 3. NLP æ ¸å¿ƒå·¥å…·å‡½æ•° =================

# å®šä¹‰åœç”¨è¯ï¼šè¿™äº›è¯åœ¨è®¡ç®—ç›¸ä¼¼åº¦æ—¶ä¼šè¢«å¿½ç•¥ï¼Œä»¥çªå‡ºæ ¸å¿ƒç‰¹å¾
STOP_WORDS = {
    "åŒ»é™¢", "æœ‰é™å…¬å¸", "æœ‰é™", "è´£ä»»", "å…¬å¸", "åˆ†é™¢", "é™„å±", 
    "å­¦", "æ ¡", "å«ç”Ÿ", "æœåŠ¡", "ä¸­å¿ƒ", "ç«™", "æ‰€", "é—¨è¯Š", "éƒ¨",
    "çœ", "å¸‚", "åŒº", "å¿", "è¡—é“", "ç¤¾åŒº"
}

def extract_core_tokens(text):
    """
    ä½¿ç”¨ jieba åˆ†è¯æå–æ ¸å¿ƒç‰¹å¾è¯
    è¾“å…¥ï¼š"å››å·å¤§å­¦åè¥¿åŒ»é™¢" -> è¾“å‡ºï¼š{"å››å·å¤§å­¦", "åè¥¿"} (ç¤ºä¾‹)
    """
    if not isinstance(text, str): return set()
    
    # 1. é¢„æ¸…æ´—ï¼šå»æ‰æ‹¬å·é‡Œçš„å†…å®¹ï¼ˆé€šå¸¸æ˜¯å¤‡æ³¨ï¼‰
    text = re.sub(r'[ï¼ˆ(].*?[)ï¼‰]', '', text)
    
    # 2. æœç´¢å¼•æ“æ¨¡å¼åˆ†è¯
    words = jieba.lcut_for_search(text)
    
    tokens = set()
    for w in words:
        w = w.strip()
        # 3. è¿‡æ»¤é€»è¾‘ï¼šä¿ç•™éåœç”¨è¯ï¼Œä¸”é•¿åº¦>1çš„è¯ï¼ˆæˆ–è€…è™½çŸ­ä½†æ˜¯æ•°å­—/ç‰¹å®šå­—ï¼‰
        if w not in STOP_WORDS and len(w) > 1:
            tokens.add(w)
            
    return tokens

@st.cache_resource
def get_client():
    if not FIXED_API_KEY: return None
    return genai.Client(api_key=FIXED_API_KEY, http_options={'api_version': 'v1beta'})

@st.cache_data(ttl=3600)
def load_master_data(uploaded_file):
    """
    åŠ è½½å¹¶é¢„å¤„ç†æ ‡å‡†åº“ï¼š
    1. æ ‡å‡†åŒ–åˆ—å
    2. é¢„è®¡ç®—åˆ†è¯ Tokens (å…³é”®æ­¥éª¤)
    """
    if uploaded_file is None:
        return None, "NO_FILE"

    try:
        if uploaded_file.name.endswith('.xlsx'): 
            df = pd.read_excel(uploaded_file, engine='openpyxl')
        else: 
            df = pd.read_csv(uploaded_file)
        
        df = df.astype(str)
        df.columns = df.columns.str.strip()
        
        # ç®€å•æ¸…æ´— 'nan'
        for col in df.columns:
            df[col] = df[col].apply(lambda x: x.strip().replace('nan', '') if x != 'nan' else '')

        # åˆ—åæ˜ å°„
        col_map_rename = {}
        for col in df.columns:
            if "åç§°" in col and "åŒ»é™¢" in col: col_map_rename[col] = MASTER_COL_NAME
            elif "ç¼–ç " in col: col_map_rename[col] = MASTER_COL_CODE
            elif "çœ" in col: col_map_rename[col] = MASTER_COL_PROV
            elif "å¸‚" in col: col_map_rename[col] = MASTER_COL_CITY
        
        if col_map_rename:
            df = df.rename(columns=col_map_rename)

        required = [MASTER_COL_NAME, MASTER_COL_CODE]
        if not all(col in df.columns for col in required):
            return None, f"ç¼ºå°‘å¿…è¦åˆ—: {required}"
        
        # === æ ¸å¿ƒä¼˜åŒ–ï¼šé¢„è®¡ç®— Token ===
        # å°†æ ‡å‡†åç§°è½¬ä¸º Setï¼Œå­˜å‚¨åœ¨å†…å­˜ä¸­ï¼Œå¤§å¹…åŠ é€Ÿåç»­æ£€ç´¢
        with st.spinner("æ­£åœ¨æ„å»ºæœç´¢å¼•æ“ç´¢å¼•..."):
            df['tokens'] = df[MASTER_COL_NAME].apply(extract_core_tokens)
            
        return df, "SUCCESS"

    except Exception as e:
        return None, f"è¯»å–å¤±è´¥: {str(e)}"

def clean_json_response(text):
    text = text.replace("```json", "").replace("```", "").strip()
    try:
        return json.loads(text)
    except:
        return None

# ================= 4. å¬å›ä¸åŒ¹é…é€»è¾‘ =================

def get_candidates_by_keywords(df_master, target_name, top_k=15):
    """
    åŸºäº Jaccard ç›¸ä¼¼åº¦çš„å…¨æ–‡æ£€ç´¢
    è§£å†³ï¼šè·¨åœ°åŸŸåŒ¹é…ã€åç§°ç®€å†™åŒ¹é…
    """
    target_tokens = extract_core_tokens(str(target_name))
    if not target_tokens:
        return pd.DataFrame()

    # Jaccard è®¡ç®—å‡½æ•°
    def calc_score(master_tokens):
        if not master_tokens: return 0.0
        intersection = len(target_tokens & master_tokens)
        union = len(target_tokens | master_tokens)
        if union == 0: return 0.0
        return intersection / union

    # è®¡ç®—å¾—åˆ† (Pandas å‘é‡åŒ– Apply)
    # æ³¨æ„ï¼šå¦‚æœ df_master > 10ä¸‡è¡Œï¼Œæ­¤å¤„éœ€è¿›ä¸€æ­¥ä¼˜åŒ–ï¼ˆå¦‚å€’æ’ç´¢å¼•ï¼‰ï¼ŒStreamlit åœºæ™¯ä¸‹é€šå¸¸å¤Ÿç”¨
    scores = df_master['tokens'].apply(calc_score)
    
    # ç­›é€‰æœ‰é‡åˆè¯ä¸”å¾—åˆ†è¾ƒé«˜çš„è¡Œ
    # é˜ˆå€¼ 0.3 æ„å‘³ç€å¤§çº¦æœ‰ 1/3 çš„ç‰¹å¾è¯é‡åˆ
    valid_mask = scores > 0.25 
    if not valid_mask.any():
        return pd.DataFrame()
        
    candidates = df_master.loc[valid_mask].copy()
    candidates['sim_score'] = scores[valid_mask]
    
    # å–å‰ K ä¸ª
    candidates = candidates.sort_values('sim_score', ascending=False).head(top_k)
    candidates['__source__'] = 'å…³é”®è¯å¬å›(å¼‚åœ°/æ¨¡ç³Š)'
    
    return candidates

def get_candidates_smart(df_master, mapping, target_name, target_prov, target_city):
    """
    æ··åˆå¬å›ç­–ç•¥ï¼š
    1. åŒåŸå¬å› (Geo-Fence) -> ä¿è¯åœ°åŸŸå‡†ç¡®æ€§
    2. å…³é”®è¯å¬å› (Keyword Search) -> ä¿è¯åç§°å‡†ç¡®æ€§ï¼ˆå®¹é”™åŸå¸‚å¡«å†™ï¼‰
    """
    candidates_list = []
    
    # --- ç­–ç•¥ A: åŒåŸå¬å› ---
    if target_city and target_city != "nan":
        df_geo = df_master[df_master[MASTER_COL_CITY] == target_city].copy()
        if not df_geo.empty:
            df_geo['__source__'] = 'åŒåŸèŒƒå›´'
            # é™åˆ¶æ•°é‡ï¼Œé˜²æ­¢ Token æº¢å‡º
            candidates_list.append(df_geo.head(30))

    # --- ç­–ç•¥ B: å…³é”®è¯å¬å› ---
    # åªæœ‰å½“åå­—æœ‰å®è´¨å†…å®¹æ—¶æ‰æœ
    if len(str(target_name)) >= 2:
        df_keyword = get_candidates_by_keywords(df_master, target_name, top_k=15)
        if not df_keyword.empty:
            candidates_list.append(df_keyword)

    if not candidates_list:
        return pd.DataFrame()
    
    # --- åˆå¹¶ä¸å»é‡ ---
    final = pd.concat(candidates_list)
    # æŒ‰ç¼–ç å»é‡ï¼Œå¦‚æœåŒä¸€å®¶åŒ»é™¢æ—¢åœ¨åŒåŸåˆè¢«æœå‡ºæ¥äº†ï¼Œä¿ç•™ä¸€ä»½
    final = final.drop_duplicates(subset=[MASTER_COL_CODE])
    
    return final

def call_ai_matching(client, target_name, target_prov, target_city, candidates_df):
    """
    AI å†³ç­–ï¼šåŸºäºæ··åˆå€™é€‰æ± è¿›è¡Œæœ€ç»ˆåˆ¤æ–­
    """
    candidate_list_str = ""
    candidate_map = {} 
    
    for idx, row in candidates_df.iterrows():
        key = str(idx) 
        source_tag = row.get('__source__', 'æœªçŸ¥')
        # æ„é€ ä¸Šä¸‹æ–‡
        info = f"ID:{key} | åç§°:{row[MASTER_COL_NAME]} | åŒºåŸŸ:{row[MASTER_COL_PROV]}-{row[MASTER_COL_CITY]} | æ¥æº:[{source_tag}]"
        candidate_list_str += info + "\n"
        candidate_map[key] = row
        
    if not candidate_list_str:
        return None 

    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªåŒ»ç–—ä¸»æ•°æ®å¯¹é½ä¸“å®¶ã€‚
    ã€ä»»åŠ¡ç›®æ ‡ã€‘åˆ¤æ–­ã€å¾…æ¸…æ´—æ•°æ®ã€‘æ˜¯å¦å¯¹åº”åˆ—è¡¨ä¸­çš„æŸå®¶æ ‡å‡†æœºæ„ã€‚
    
    ã€å¾…æ¸…æ´—æ•°æ®ã€‘
    åç§°: {target_name}
    ä½ç½®: {target_prov} - {target_city}
    
    ã€å€™é€‰åˆ—è¡¨ã€‘(æ³¨æ„æ¥æºæ ‡ç­¾)
    {candidate_list_str}
    
    ã€æ ¸å¿ƒæ¨ç†é€»è¾‘ã€‘
    1. **è¯†åˆ«æœ‰æ•ˆä¿¡æ¯**ï¼šå¾…æ¸…æ´—æ•°æ®çš„ã€åŸå¸‚ã€‘å¯èƒ½å¡«é”™ï¼Œä½†ã€åç§°ã€‘ä¸­çš„ä¸“æœ‰åè¯ï¼ˆå¦‚"åå’Œ"ã€"åè¥¿"ã€"çœç«‹"ï¼‰é€šå¸¸æ˜¯å‡†ç¡®çš„ã€‚
    
    2. **ä¼˜å…ˆçº§åˆ¤å®š**ï¼š
       - **Case A (åŸå¸‚é”™è¯¯ä¿®æ­£)**ï¼šå¦‚æœ `æ¥æº:[å…³é”®è¯å¬å›]` ä¸­æœ‰åç§°**é«˜åº¦ä¸€è‡´**ï¼ˆåŒ…å«ç›¸åŒçš„æ ¸å¿ƒç‰¹æŒ‡è¯ï¼‰çš„æœºæ„ï¼Œå³ä½¿åŸå¸‚ä¸ç¬¦ï¼Œä¹Ÿåº”åˆ¤å®šä¸ºåŒ¹é…ï¼ˆè§†ä¸ºç”¨æˆ·å¡«é”™åœ°å€ï¼‰ã€‚
         - ä¾‹ï¼šç”¨æˆ·å¡«"å—äº¬-åè¥¿åŒ»é™¢"ï¼Œå€™é€‰ä¸­åªæœ‰"æˆéƒ½-å››å·å¤§å­¦åè¥¿åŒ»é™¢"ï¼Œåˆ¤å®šåŒ¹é…ã€‚
       - **Case B (åŒåŸå¸¸è§„åŒ¹é…)**ï¼šåœ¨ `æ¥æº:[åŒåŸèŒƒå›´]` ä¸­å¯»æ‰¾åç§°å«ä¹‰ä¸€è‡´çš„æœºæ„ï¼ˆåŒ…æ‹¬åˆ«åã€ç®€ç§°ï¼‰ã€‚
       
    3. **ç±»å‹ä¸€è‡´æ€§æ ¡éªŒ**ï¼š
       - ä¸¥ç¦å°†"å«ç”Ÿå®¤"åŒ¹é…åˆ°"ç»¼åˆåŒ»é™¢"ã€‚
       - ä¸¥ç¦å°†"åˆ†é™¢"åŒ¹é…åˆ°"æ€»é™¢"ï¼Œé™¤éæ²¡æœ‰æ›´å¥½çš„é€‰æ‹©ä¸”æ˜ç¡®æ˜¯ä»å±å…³ç³»ã€‚
       
    4. **æ— æ³•ç¡®å®š**ï¼š
       - å¦‚æœåˆ—è¡¨é‡Œæ²¡æœ‰åˆé€‚çš„ï¼Œè¿”å› nullã€‚
    
    ã€è¾“å‡º JSON æ ¼å¼ã€‘
    {{
        "matched_id": "å€™é€‰ID (String) æˆ– null",
        "confidence": 0.0-1.0,
        "reason": "ç®€è¿°ç†ç”±ï¼Œå¦‚ï¼š'åç§°åŒ…å«æ ¸å¿ƒè¯xxï¼Œåˆ¤å®šä¸ºåŒçœå¼‚åœ°åŒ¹é…' æˆ– 'åŒåŸå…¨ç§°åŒ¹é…'"
    }}
    """
    
    try:
        response = client.models.generate_content(
            model=MODEL_NAME, 
            contents=prompt,
            config=types.GenerateContentConfig(response_mime_type="application/json")
        )
        result = clean_json_response(response.text)
        
        if result and result.get('matched_id'):
            matched_id = str(result['matched_id'])
            if matched_id in candidate_map:
                matched_row = candidate_map[matched_id]
                return {
                    "æ ‡å‡†ç¼–ç ": matched_row[MASTER_COL_CODE],
                    "æ ‡å‡†åç§°": matched_row[MASTER_COL_NAME],
                    "æ ‡å‡†çœä»½": matched_row[MASTER_COL_PROV],
                    "æ ‡å‡†åŸå¸‚": matched_row[MASTER_COL_CITY],
                    "ç½®ä¿¡åº¦": result.get('confidence', 0.5),
                    "åŒ¹é…åŸå› ": result.get('reason', 'AIæ¨ç†'),
                    "åŒ¹é…çŠ¶æ€": "AIåŒ¹é…"
                }
        
        return {
            "åŒ¹é…åŸå› ": result.get('reason', 'æœªåœ¨å€™é€‰ä¸­æ‰¾åˆ°') if result else "AIè¿”å›æ ¼å¼æ— æ•ˆ",
            "åŒ¹é…çŠ¶æ€": "AIæœªåŒ¹é…"
        }
            
    except Exception as e:
        return {"åŒ¹é…åŸå› ": f"APIå¼‚å¸¸: {str(e)}", "åŒ¹é…çŠ¶æ€": "é”™è¯¯"}

# ================= 5. åˆå§‹åŒ–ä¸ä¾§è¾¹æ  =================

inject_custom_css()
client = get_client()

if "df_result" not in st.session_state: st.session_state.df_result = None
if "mapping_confirmed" not in st.session_state: st.session_state.mapping_confirmed = False
if "processing" not in st.session_state: st.session_state.processing = False
if "stop_signal" not in st.session_state: st.session_state.stop_signal = False
if "col_map" not in st.session_state: st.session_state.col_map = {}

with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/3063/3063823.png", width=60)
    st.title("ChatMDM")
    st.caption("Mixed-Strategy Edition")
    st.markdown("---")

    st.markdown("### 1ï¸âƒ£ å‡†å¤‡æ ‡å‡†åº“")
    st.info("ä¸Šä¼ æ–‡ä»¶æ—¶å°†è‡ªåŠ¨æ„å»ºå…³é”®è¯ç´¢å¼•")
    master_file = st.file_uploader("ä¸Šä¼  mdm.xlsx / .csv", type=["xlsx", "csv"], key="master_uploader")

    df_master = None
    if master_file:
        df_master, msg = load_master_data(master_file)
        if df_master is not None:
            st.success(f"âœ… ç´¢å¼•æ„å»ºå®Œæˆ: {len(df_master):,} æ¡")
        else:
            st.error(msg)
    else:
        st.warning("ğŸ‘ˆ ç­‰å¾…ä¸Šä¼ æ ‡å‡†åº“")

    st.markdown("---")
    if st.button("ğŸ”„ é‡ç½®ä»»åŠ¡", use_container_width=True):
        st.session_state.clear()
        st.rerun()
        
    if st.session_state.df_result is not None:
        st.divider()
        st.markdown("### ğŸ“¥ ç»“æœå¯¼å‡º")
        df_exp = st.session_state.df_result
        done_cnt = len(df_exp[df_exp['åŒ¹é…çŠ¶æ€'] != 'å¾…å¤„ç†'])
        match_cnt = len(df_exp[df_exp['æ ‡å‡†ç¼–ç '].notna()])
        st.caption(f"è¿›åº¦: {done_cnt}/{len(df_exp)} | å‘½ä¸­: {match_cnt}")
        csv = df_exp.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ä¸‹è½½ç»“æœ", data=csv, file_name="mdm_result.csv", mime="text/csv", type="primary")

# ================= 6. ä¸»é€»è¾‘ =================

st.title("ğŸ¥ åŒ»ç–—ä¸»æ•°æ®æ™ºèƒ½å¯¹é½ç³»ç»Ÿ")

if not FIXED_API_KEY:
    st.warning("âš ï¸ è¯·é…ç½® GENAI_API_KEY")

if df_master is None:
    st.info("ğŸ‘‹ è¯·å…ˆä»å·¦ä¾§ä¸Šä¼ æ ‡å‡†åº“")
    st.stop()

# --- Phase 1: ä¸Šä¼  ---
if st.session_state.df_result is None:
    st.markdown("### 2ï¸âƒ£ ä¸Šä¼ å¾…æ¸…æ´—æ•°æ®")
    uploaded_file = st.file_uploader("æ”¯æŒ Excel / CSV", type=["xlsx", "csv"], key="target_uploader")
    
    if uploaded_file:
        try:
            if uploaded_file.name.endswith('.csv'): df_temp = pd.read_csv(uploaded_file)
            else: df_temp = pd.read_excel(uploaded_file, engine='openpyxl')
            
            df_temp = df_temp.astype(str)
            for col in ['åŒ¹é…çŠ¶æ€', 'æ ‡å‡†ç¼–ç ', 'æ ‡å‡†åç§°', 'æ ‡å‡†çœä»½', 'æ ‡å‡†åŸå¸‚', 'åŒ¹é…åŸå› ']:
                df_temp[col] = None
            df_temp['åŒ¹é…çŠ¶æ€'] = 'å¾…å¤„ç†'
            df_temp['ç½®ä¿¡åº¦'] = 0.0
            
            st.session_state.df_result = df_temp
            st.rerun()
        except Exception as e:
            st.error(f"è¯»å–å¤±è´¥: {e}")

# --- Phase 2: æ˜ å°„ ---
elif not st.session_state.mapping_confirmed:
    st.markdown("### 3ï¸âƒ£ å­—æ®µæ˜ å°„")
    df_cols = st.session_state.df_result.columns.tolist()
    c1, c2, c3 = st.columns(3)
    with c1: t_name = st.selectbox("ã€åç§°ã€‘åˆ—", df_cols)
    with c2: t_prov = st.selectbox("ã€çœä»½ã€‘åˆ— (å¯é€‰)", ["æ— "] + df_cols)
    with c3: t_city = st.selectbox("ã€åŸå¸‚ã€‘åˆ— (å¯é€‰)", ["æ— "] + df_cols)

    if st.button("å¼€å§‹å¤„ç†", type="primary"):
        st.session_state.col_map = {"target_name": t_name, "target_province": t_prov, "target_city": t_city}
        st.session_state.mapping_confirmed = True
        st.rerun()

# --- Phase 3: æ§åˆ¶å° ---
else:
    df_curr = st.session_state.df_result
    col_map = st.session_state.col_map
    
    total = len(df_curr)
    done_cnt = len(df_curr[df_curr['åŒ¹é…çŠ¶æ€'] != 'å¾…å¤„ç†'])
    
    c1, c2, c3, c4 = st.columns(4)
    with c1: render_metric_card("è¿›åº¦", f"{done_cnt}/{total}")
    with c2: render_metric_card("å…¨å­—åŒ¹é…", len(df_curr[df_curr['åŒ¹é…çŠ¶æ€'] == 'å…¨å­—åŒ¹é…']))
    with c3: render_metric_card("AI åŒ¹é…", len(df_curr[df_curr['åŒ¹é…çŠ¶æ€'] == 'AIåŒ¹é…']))
    with c4: render_metric_card("æœªåŒ¹é…", len(df_curr[df_curr['åŒ¹é…çŠ¶æ€'] == 'AIæœªåŒ¹é…']))
    
    st.divider()
    
    col_ctrl, col_status = st.columns([1, 3])
    with col_ctrl:
        # ç²¾ç¡®åŒ¹é…é€»è¾‘ (Hash)
        if st.button("âš¡ ç²¾ç¡®åŒ¹é… (Hash)", use_container_width=True, disabled=st.session_state.processing):
            with st.spinner("Hash æ¯”å¯¹ä¸­..."):
                t_name = col_map['target_name']
                master_dict = {str(k).strip(): v for k, v in df_master.drop_duplicates(subset=[MASTER_COL_NAME]).set_index(MASTER_COL_NAME).to_dict('index').items()}
                
                for idx, row in df_curr.iterrows():
                    if row['åŒ¹é…çŠ¶æ€'] != 'å¾…å¤„ç†': continue
                    val = str(row[t_name]).strip()
                    if val in master_dict:
                        match = master_dict[val]
                        df_curr.at[idx, 'æ ‡å‡†ç¼–ç '] = match.get(MASTER_COL_CODE)
                        df_curr.at[idx, 'æ ‡å‡†åç§°'] = val
                        df_curr.at[idx, 'æ ‡å‡†çœä»½'] = match.get(MASTER_COL_PROV)
                        df_curr.at[idx, 'æ ‡å‡†åŸå¸‚'] = match.get(MASTER_COL_CITY)
                        df_curr.at[idx, 'åŒ¹é…çŠ¶æ€'] = 'å…¨å­—åŒ¹é…'
                        df_curr.at[idx, 'ç½®ä¿¡åº¦'] = 1.0
                st.session_state.df_result = df_curr
                st.rerun()

        # AI åŒ¹é…æŒ‰é’®
        if not st.session_state.processing:
            if st.button("ğŸ§  AI æ·±åº¦åŒ¹é…", type="primary", use_container_width=True):
                st.session_state.processing = True
                st.session_state.stop_signal = False
                st.rerun()
        else:
            if st.button("ğŸ›‘ æš‚åœ", type="secondary", use_container_width=True):
                st.session_state.stop_signal = True
                st.session_state.processing = False
                st.rerun()

    with col_status:
        progress_bar = st.progress(0)
        status_text = st.empty()
        table_placeholder = st.empty()
        
        table_placeholder.dataframe(
            df_curr, 
            use_container_width=True, 
            column_order=['åŒ¹é…çŠ¶æ€', 'ç½®ä¿¡åº¦', 'åŒ¹é…åŸå› ', col_map['target_name'], 'æ ‡å‡†åç§°'],
            height=300
        )
        
        if st.session_state.processing:
            pending_indices = df_curr[df_curr['åŒ¹é…çŠ¶æ€'] == 'å¾…å¤„ç†'].index.tolist()
            
            if not pending_indices:
                st.session_state.processing = False
                st.success("å…¨éƒ¨å®Œæˆ")
                st.rerun()
            
            for i, idx in enumerate(pending_indices):
                if st.session_state.stop_signal:
                    st.session_state.processing = False
                    st.warning("å·²æš‚åœ")
                    st.rerun()
                    break
                
                row = df_curr.loc[idx]
                t_n = str(row[col_map['target_name']])
                t_p = str(row[col_map['target_province']]) if col_map['target_province'] != "æ— " else ""
                t_c = str(row[col_map['target_city']]) if col_map['target_city'] != "æ— " else ""
                
                status_text.text(f"æ­£åœ¨å¤„ç†: {t_n}")
                progress_bar.progress((i + 1) / len(pending_indices))
                
                # --- æ ¸å¿ƒè°ƒç”¨ ---
                candidates = get_candidates_smart(df_master, col_map, t_n, t_p, t_c)
                
                if len(candidates) > 0:
                    ai_res = call_ai_matching(client, t_n, t_p, t_c, candidates)
                    for k, v in ai_res.items():
                        if k in df_curr.columns: df_curr.at[idx, k] = v
                else:
                    df_curr.at[idx, 'åŒ¹é…çŠ¶æ€'] = 'æ— å€™é€‰'
                    df_curr.at[idx, 'åŒ¹é…åŸå› '] = 'åŒåŸ/å…³é”®è¯å‡æœªå¬å›è¿‘ä¼¼æ•°æ®'

                if i % 3 == 0:
                    st.session_state.df_result = df_curr
                    table_placeholder.dataframe(
                        df_curr, 
                        use_container_width=True, 
                        column_order=['åŒ¹é…çŠ¶æ€', 'ç½®ä¿¡åº¦', 'åŒ¹é…åŸå› ', col_map['target_name'], 'æ ‡å‡†åç§°'],
                        height=300
                    )
            
            st.session_state.df_result = df_curr
            st.session_state.processing = False
            st.success("é˜Ÿåˆ—å¤„ç†å®Œæ¯•")
            st.rerun()

