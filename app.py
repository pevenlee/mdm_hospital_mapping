import streamlit as st
import pandas as pd
import json
import warnings
import os
import time
import re
import jieba
import concurrent.futures
from google import genai
from google.genai import types

# å¿½ç•¥æ— å…³è­¦å‘Š
warnings.filterwarnings('ignore')

# ================= 1. åŸºç¡€é…ç½® =================

st.set_page_config(
    page_title="ChatMDM - æé€Ÿå¹¶å‘ç‰ˆ", 
    layout="wide", 
    initial_sidebar_state="expanded"
)

# --- æ¨¡å‹é…ç½® ---
MODEL_NAME = "gemini-3-pro-preview" # å»ºè®®ä½¿ç”¨ flash æ¨¡å‹ï¼Œé€Ÿåº¦æ›´å¿«ä¸”è¶³å¤Ÿå¤„ç†æ­¤ç±»ä»»åŠ¡ï¼Œæˆ–è€…æ¢å›ä½ çš„ "gemini-1.5-pro"

# --- å…¨å±€å¸¸é‡ ---
MASTER_COL_NAME = "åŒ»é™¢åç§°"
MASTER_COL_CODE = "åŒ»é™¢ç¼–ç "
MASTER_COL_PROV = "çœä»½"
MASTER_COL_CITY = "åŸå¸‚"
CACHE_FILE = "mdm_cache.pkl"

# --- API Key è§£æ ---
try:
    keys_str = st.secrets.get("GENAI_API_KEY", os.getenv("GENAI_API_KEY", ""))
    API_KEYS = [k.strip() for k in keys_str.split(',') if k.strip()]
    if not API_KEYS:
        API_KEYS = [""]
except:
    API_KEYS = [""]

# ================= 2. è§†è§‰ä½“ç³» =================

def inject_custom_css():
    st.markdown("""
        <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');
        
        .stApp {
            background-color: #050505;
            background-image: radial-gradient(circle at 50% 0%, #1a1a2e 0%, #050505 40%);
            font-family: 'Inter', "Microsoft YaHei", sans-serif;
        }
        
        .glass-card {
            background: rgba(255, 255, 255, 0.03);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.08);
            border-radius: 12px;
            padding: 20px;
            margin-bottom: 20px;
        }
        
        .metric-label { font-size: 12px; color: #94a3b8; text-transform: uppercase; letter-spacing: 1px; }
        .metric-value { font-size: 28px; font-weight: 700; color: #ffffff; }
        .metric-sub { font-size: 12px; color: #64748b; margin-top: 4px; }
        
        [data-testid="stSidebar"] { background-color: #000000 !important; border-right: 1px solid #222; }
        [data-testid="stDataFrame"] { border: 1px solid #333; border-radius: 8px; }
        .stProgress > div > div > div > div { background-color: #3b82f6; }
        </style>
    """, unsafe_allow_html=True)

def render_metric_card(label, value, sub_text=""):
    st.markdown(f"""
    <div class="glass-card">
        <div class="metric-label">{label}</div>
        <div class="metric-value">{value}</div>
        <div class="metric-sub">{sub_text}</div>
    </div>
    """, unsafe_allow_html=True)

# ================= 3. NLP & æ•°æ®å¤„ç†å·¥å…· =================

STOP_WORDS = {
    "åŒ»é™¢", "æœ‰é™å…¬å¸", "æœ‰é™", "è´£ä»»", "å…¬å¸", "åˆ†é™¢", "é™„å±", 
    "å­¦", "æ ¡", "å«ç”Ÿ", "æœåŠ¡", "ä¸­å¿ƒ", "ç«™", "æ‰€", "é—¨è¯Š", "éƒ¨",
    "çœ", "å¸‚", "åŒº", "å¿", "è¡—é“", "ç¤¾åŒº"
}

def extract_core_tokens(text):
    if not isinstance(text, str): return set()
    text = re.sub(r'[ï¼ˆ(].*?[)ï¼‰]', '', text)
    words = jieba.lcut_for_search(text)
    tokens = set()
    for w in words:
        w = w.strip()
        if w not in STOP_WORDS and len(w) > 1:
            tokens.add(w)
    return tokens

@st.cache_resource
def get_clients():
    clients = []
    for key in API_KEYS:
        if key:
            clients.append(genai.Client(api_key=key, http_options={'api_version': 'v1beta'}))
    return clients

# --- ç¼“å­˜ç®¡ç† ---

def load_cached_master():
    if os.path.exists(CACHE_FILE):
        try:
            df = pd.read_pickle(CACHE_FILE)
            return df
        except Exception as e:
            return None
    return None

def save_master_cache(df):
    try:
        df.to_pickle(CACHE_FILE)
    except Exception as e:
        st.error(f"ç¼“å­˜å†™å…¥å¤±è´¥: {e}")

def clear_master_cache():
    if os.path.exists(CACHE_FILE):
        os.remove(CACHE_FILE)

# --- æ•°æ®åŠ è½½ ---

def process_master_data(uploaded_file):
    try:
        if uploaded_file.name.endswith('.xlsx'): 
            df = pd.read_excel(uploaded_file, engine='openpyxl')
        else: 
            df = pd.read_csv(uploaded_file)
        
        df = df.astype(str)
        df.columns = df.columns.str.strip()
        
        for col in df.columns:
            df[col] = df[col].apply(lambda x: x.strip().replace('nan', '') if x != 'nan' else '')

        col_map_rename = {}
        for col in df.columns:
            if "åç§°" in col and "åŒ»é™¢" in col: col_map_rename[col] = MASTER_COL_NAME
            elif "ç¼–ç " in col: col_map_rename[col] = MASTER_COL_CODE
            elif "çœ" in col: col_map_rename[col] = MASTER_COL_PROV
            elif "å¸‚" in col: col_map_rename[col] = MASTER_COL_CITY
        
        if col_map_rename:
            df = df.rename(columns=col_map_rename)

        required = [MASTER_COL_NAME, MASTER_COL_CODE]
        if not all(col in df.columns for col in required):
            return None, f"ç¼ºå°‘å¿…è¦åˆ—: {required}"
        
        with st.spinner("æ­£åœ¨æ„å»ºæœç´¢å¼•æ“ç´¢å¼•..."):
            df['tokens'] = df[MASTER_COL_NAME].apply(extract_core_tokens)
            
        return df, "SUCCESS"

    except Exception as e:
        return None, f"è¯»å–å¤±è´¥: {str(e)}"

def clean_json_response(text):
    text = text.replace("```json", "").replace("```", "").strip()
    try:
        return json.loads(text)
    except:
        return None

# ================= 4. å¬å›ä¸åŒ¹é…é€»è¾‘ =================

def get_candidates_by_keywords(df_master, target_name, top_k=15):
    # ç®€å•çš„å…³é”®è¯é‡å è®¡ç®—ï¼Œä¸ä½¿ç”¨ apply ä»¥æé«˜é€Ÿåº¦ï¼ˆå¦‚æœæ•°æ®é‡æå¤§ï¼Œå»ºè®®ä½¿ç”¨å€’æ’ç´¢å¼•ï¼‰
    target_tokens = extract_core_tokens(str(target_name))
    if not target_tokens: return pd.DataFrame()

    # è¿™é‡Œçš„æ€§èƒ½ç“¶é¢ˆåœ¨äºå¤§è¡¨æ‰«æï¼Œåç»­å¯ä¼˜åŒ–ä¸ºå€’æ’ç´¢å¼•
    def calc_score(master_tokens):
        if not master_tokens: return 0.0
        intersection = len(target_tokens & master_tokens)
        union = len(target_tokens | master_tokens)
        if union == 0: return 0.0
        return intersection / union

    scores = df_master['tokens'].apply(calc_score)
    valid_mask = scores > 0.25 
    if not valid_mask.any(): return pd.DataFrame()
        
    candidates = df_master.loc[valid_mask].copy()
    candidates['sim_score'] = scores[valid_mask]
    
    candidates = candidates.sort_values('sim_score', ascending=False).head(top_k)
    candidates['__source__'] = 'å…³é”®è¯å¬å›'
    return candidates

def get_candidates_smart(df_master, col_map, target_name, target_prov, target_city):
    candidates_list = []
    
    # ç­–ç•¥ A: åŒåŸ
    if target_city and target_city != "nan" and len(target_city) > 1:
        # ä¼˜åŒ–ï¼šé¢„å…ˆç­›é€‰ï¼Œé¿å…åœ¨å¤§ DataFrame ä¸Šåšå­—ç¬¦ä¸²æ“ä½œ
        df_geo = df_master[df_master[MASTER_COL_CITY] == target_city].copy()
        if not df_geo.empty:
            df_geo['__source__'] = 'åŒåŸèŒƒå›´'
            candidates_list.append(df_geo.head(30))

    # ç­–ç•¥ B: å…³é”®è¯
    if len(str(target_name)) >= 2:
        df_keyword = get_candidates_by_keywords(df_master, target_name, top_k=15)
        if not df_keyword.empty:
            candidates_list.append(df_keyword)

    if not candidates_list: return pd.DataFrame()
    
    final = pd.concat(candidates_list)
    final = final.drop_duplicates(subset=[MASTER_COL_CODE])
    return final

def call_ai_matching(client, target_name, target_prov, target_city, candidates_df):
    candidate_list_str = ""
    candidate_map = {} 
    
    # åªå–å‰ 20 ä¸ªå€™é€‰å‡å°‘ Prompt é•¿åº¦
    candidates_df = candidates_df.head(100)
    
    for idx, row in candidates_df.iterrows():
        key = str(idx) 
        source_tag = row.get('__source__', 'æœªçŸ¥')
        info = f"ID:{key} | åç§°:{row[MASTER_COL_NAME]} | åŒºåŸŸ:{row.get(MASTER_COL_PROV,'')}-{row.get(MASTER_COL_CITY,'')} | æ¥æº:[{source_tag}]"
        candidate_list_str += info + "\n"
        candidate_map[key] = row
        
    if not candidate_list_str: return None 

    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªåŒ»ç–—ä¸»æ•°æ®å¯¹é½ä¸“å®¶ã€‚è¯·åˆ¤æ–­ã€å¾…æ¸…æ´—æ•°æ®ã€‘æ˜¯å¦å¯¹åº”åˆ—è¡¨ä¸­çš„æŸå®¶æ ‡å‡†æœºæ„ã€‚
    
    ã€å¾…æ¸…æ´—æ•°æ®ã€‘
    åç§°: {target_name}
    ä½ç½®: {target_prov} - {target_city}
    
    ã€å€™é€‰åˆ—è¡¨ã€‘
    {candidate_list_str}
    
    ã€è§„åˆ™ã€‘
    1. å³ä½¿åŸå¸‚ä¸ç¬¦ï¼Œè‹¥åç§°æ ¸å¿ƒä¸“æœ‰åè¯é«˜åº¦ä¸€è‡´ï¼Œä¹Ÿåº”åŒ¹é…ï¼ˆå¯èƒ½æ˜¯åŸå¸‚å¡«é”™ï¼‰ã€‚
    2. ä¸¥ç¦å°†"å«ç”Ÿå®¤"åŒ¹é…åˆ°"ç»¼åˆåŒ»é™¢"ã€‚
    3. è‹¥æ— åŒ¹é…ï¼Œè¿”å› nullã€‚
    
    ã€è¾“å‡º JSONã€‘
    {{
        "matched_id": "å€™é€‰ID (String) æˆ– null",
        "confidence": 0.0-1.0,
        "reason": "ç®€çŸ­ç†ç”±"
    }}
    """
    
    try:
        response = client.models.generate_content(
            model=MODEL_NAME, 
            contents=prompt,
            config=types.GenerateContentConfig(response_mime_type="application/json")
        )
        result = clean_json_response(response.text)
        
        if result and result.get('matched_id'):
            matched_id = str(result['matched_id'])
            if matched_id in candidate_map:
                matched_row = candidate_map[matched_id]
                return {
                    "æ ‡å‡†ç¼–ç ": matched_row[MASTER_COL_CODE],
                    "æ ‡å‡†åç§°": matched_row[MASTER_COL_NAME],
                    "æ ‡å‡†çœä»½": matched_row[MASTER_COL_PROV],
                    "æ ‡å‡†åŸå¸‚": matched_row[MASTER_COL_CITY],
                    "ç½®ä¿¡åº¦": result.get('confidence', 0.5),
                    "åŒ¹é…åŸå› ": result.get('reason', 'AIæ¨ç†'),
                    "åŒ¹é…çŠ¶æ€": "AIåŒ¹é…"
                }
        return {"åŒ¹é…åŸå› ": result.get('reason', 'æœªæ‰¾åˆ°') if result else "JSONæ— æ•ˆ", "åŒ¹é…çŠ¶æ€": "AIæœªåŒ¹é…"}
            
    except Exception as e:
        return {"åŒ¹é…åŸå› ": f"APIå¼‚å¸¸: {str(e)}", "åŒ¹é…çŠ¶æ€": "é”™è¯¯"}

def process_row_job(idx, row_data, df_master, col_map, client):
    """
    çº¯ç²¹çš„åå°è®¡ç®—å‡½æ•°ï¼Œä¸åŒ…å«ä»»ä½• Streamlit UI æ“ä½œ
    """
    t_n = str(row_data[col_map['target_name']])
    t_p = str(row_data[col_map['target_province']]) if col_map['target_province'] != "æ— " else ""
    t_c = str(row_data[col_map['target_city']]) if col_map['target_city'] != "æ— " else ""
    
    # 1. å¬å›
    candidates = get_candidates_smart(df_master, col_map, t_n, t_p, t_c)
    
    result_update = {
        "idx": idx, # å¿…é¡»æŠŠ index ä¼ å›æ¥ä»¥ä¾¿åˆå¹¶
        "åŒ¹é…çŠ¶æ€": "AIæœªåŒ¹é…",
        "åŒ¹é…åŸå› ": "æ— å€™é€‰æ•°æ®",
        "æ ‡å‡†ç¼–ç ": None,
        "æ ‡å‡†åç§°": None,
        "æ ‡å‡†çœä»½": None,
        "æ ‡å‡†åŸå¸‚": None,
        "ç½®ä¿¡åº¦": 0.0
    }
    
    # 2. åŒ¹é…
    if len(candidates) > 0:
        ai_res = call_ai_matching(client, t_n, t_p, t_c, candidates)
        if ai_res:
            result_update.update(ai_res)
    else:
        result_update["åŒ¹é…åŸå› "] = "åŒåŸ/å…³é”®è¯å‡æœªå¬å›"
        
    return result_update

# ================= 5. åˆå§‹åŒ–ä¸ä¾§è¾¹æ é€»è¾‘ =================

inject_custom_css()
clients = get_clients()

if "df_result" not in st.session_state: st.session_state.df_result = None
if "mapping_confirmed" not in st.session_state: st.session_state.mapping_confirmed = False
if "processing" not in st.session_state: st.session_state.processing = False
if "stop_signal" not in st.session_state: st.session_state.stop_signal = False
if "col_map" not in st.session_state: st.session_state.col_map = {}
if "df_master" not in st.session_state: st.session_state.df_master = load_cached_master()

with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/3063/3063823.png", width=60)
    st.title("ChatMDM")
    st.caption("High-Performance Concurrent")
    st.markdown("---")

    st.markdown("### 1ï¸âƒ£ æ ‡å‡†åº“ç®¡ç†")
    
    if st.session_state.df_master is not None:
        st.success(f"âœ… å·²åŠ è½½ç¼“å­˜æ ‡å‡†åº“\n\næ•°æ®é‡: {len(st.session_state.df_master):,} æ¡")
        
        if st.button("ğŸ—‘ï¸ åˆ é™¤ç¼“å­˜ / æ›´æ¢æ–‡ä»¶"):
            clear_master_cache()
            st.session_state.df_master = None
            st.rerun()
    else:
        st.info("é¦–æ¬¡è¿è¡Œè¯·ä¸Šä¼  mdm.xlsx")
        master_file = st.file_uploader("ä¸Šä¼ æ–‡ä»¶ (è‡ªåŠ¨å»ºç«‹ç´¢å¼•ç¼“å­˜)", type=["xlsx", "csv"], key="master_uploader")

        if master_file:
            df_processed, msg = process_master_data(master_file)
            if df_processed is not None:
                st.session_state.df_master = df_processed
                save_master_cache(df_processed)
                st.success("ç´¢å¼•æ„å»ºå®Œæˆå¹¶å·²ç¼“å­˜ï¼")
                time.sleep(1)
                st.rerun()
            else:
                st.error(msg)

    st.markdown("---")
    
    if st.button("ğŸ”„ é‡ç½®ä»»åŠ¡ (ä¿ç•™æ ‡å‡†åº“)", use_container_width=True):
        saved_master = st.session_state.df_master
        st.session_state.clear()
        st.session_state.df_master = saved_master
        st.rerun()
        
    if st.session_state.df_result is not None:
        st.divider()
        st.markdown("### ğŸ“¥ ç»“æœå¯¼å‡º")
        df_exp = st.session_state.df_result
        done_cnt = len(df_exp[df_exp['åŒ¹é…çŠ¶æ€'] != 'å¾…å¤„ç†'])
        match_cnt = len(df_exp[df_exp['æ ‡å‡†ç¼–ç '].notna()])
        st.caption(f"è¿›åº¦: {done_cnt}/{len(df_exp)} | å‘½ä¸­: {match_cnt}")
        csv = df_exp.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ä¸‹è½½ç»“æœ", data=csv, file_name="mdm_result.csv", mime="text/csv", type="primary")

# ================= 6. ä¸»é€»è¾‘ =================

st.title("ğŸ¥ åŒ»ç–—ä¸»æ•°æ®æ™ºèƒ½å¯¹é½ç³»ç»Ÿ (æé€Ÿç‰ˆ)")

if not clients:
    st.warning("âš ï¸ è¯·é…ç½® GENAI_API_KEY")

if st.session_state.df_master is None:
    st.info("ğŸ‘‹ æ¬¢è¿ï¼è¯·ä»å·¦ä¾§ä¸Šä¼ æ ‡å‡†åº“ä»¥å¼€å§‹ã€‚")
    st.stop()
else:
    df_master = st.session_state.df_master 

# --- Phase 1: ä¸Šä¼  ---
if st.session_state.df_result is None:
    st.markdown("### 2ï¸âƒ£ ä¸Šä¼ å¾…æ¸…æ´—æ•°æ®")
    uploaded_file = st.file_uploader("æ”¯æŒ Excel / CSV", type=["xlsx", "csv"], key="target_uploader")
    
    if uploaded_file:
        try:
            if uploaded_file.name.endswith('.csv'): df_temp = pd.read_csv(uploaded_file)
            else: df_temp = pd.read_excel(uploaded_file, engine='openpyxl')
            
            df_temp = df_temp.astype(str)
            for col in ['åŒ¹é…çŠ¶æ€', 'æ ‡å‡†ç¼–ç ', 'æ ‡å‡†åç§°', 'æ ‡å‡†çœä»½', 'æ ‡å‡†åŸå¸‚', 'åŒ¹é…åŸå› ']:
                df_temp[col] = None
            df_temp['åŒ¹é…çŠ¶æ€'] = 'å¾…å¤„ç†'
            df_temp['ç½®ä¿¡åº¦'] = 0.0
            
            st.session_state.df_result = df_temp
            st.rerun()
        except Exception as e:
            st.error(f"è¯»å–å¤±è´¥: {e}")

# --- Phase 2: æ˜ å°„ ---
elif not st.session_state.mapping_confirmed:
    st.markdown("### 3ï¸âƒ£ å­—æ®µæ˜ å°„")
    df_cols = st.session_state.df_result.columns.tolist()
    c1, c2, c3 = st.columns(3)
    with c1: t_name = st.selectbox("ã€åç§°ã€‘åˆ—", df_cols)
    with c2: t_prov = st.selectbox("ã€çœä»½ã€‘åˆ— (å¯é€‰)", ["æ— "] + df_cols)
    with c3: t_city = st.selectbox("ã€åŸå¸‚ã€‘åˆ— (å¯é€‰)", ["æ— "] + df_cols)

    if st.button("å¼€å§‹å¤„ç†", type="primary"):
        st.session_state.col_map = {"target_name": t_name, "target_province": t_prov, "target_city": t_city}
        st.session_state.mapping_confirmed = True
        st.rerun()

# --- Phase 3: æ§åˆ¶å° (å¹¶è¡Œå¤„ç†) ---
else:
    df_curr = st.session_state.df_result
    col_map = st.session_state.col_map
    
    # ç»Ÿè®¡æ•°æ®
    total = len(df_curr)
    done_cnt = len(df_curr[df_curr['åŒ¹é…çŠ¶æ€'] != 'å¾…å¤„ç†'])
    
    c1, c2, c3, c4 = st.columns(4)
    with c1: render_metric_card("è¿›åº¦", f"{done_cnt}/{total}")
    with c2: render_metric_card("å…¨å­—åŒ¹é…", len(df_curr[df_curr['åŒ¹é…çŠ¶æ€'] == 'å…¨å­—åŒ¹é…']))
    with c3: render_metric_card("AI åŒ¹é…", len(df_curr[df_curr['åŒ¹é…çŠ¶æ€'] == 'AIåŒ¹é…']))
    with c4: render_metric_card("æœªåŒ¹é…", len(df_curr[df_curr['åŒ¹é…çŠ¶æ€'] == 'AIæœªåŒ¹é…']))
    
    st.divider()
    
    col_ctrl, col_status = st.columns([1, 3])
    with col_ctrl:
        if st.button("âš¡ ç²¾ç¡®åŒ¹é… (Hash)", use_container_width=True, disabled=st.session_state.processing):
            with st.spinner("Hash æ¯”å¯¹ä¸­..."):
                t_name = col_map['target_name']
                # ä¼˜åŒ–ï¼šåªå–å¿…è¦çš„ä¸¤åˆ—åšå­—å…¸ï¼Œå‡å°‘å†…å­˜
                master_min = df_master[[MASTER_COL_NAME, MASTER_COL_CODE, MASTER_COL_PROV, MASTER_COL_CITY]].drop_duplicates(subset=[MASTER_COL_NAME])
                master_dict = master_min.set_index(MASTER_COL_NAME).to_dict('index')
                
                # å‘é‡åŒ–æ“ä½œä»£æ›¿è¿­ä»£ï¼Œé€Ÿåº¦æå‡ 100x
                # 1. æ‰¾åˆ°åŒ¹é…çš„ mask
                mask = (df_curr['åŒ¹é…çŠ¶æ€'] == 'å¾…å¤„ç†') & (df_curr[t_name].isin(master_dict.keys()))
                
                # 2. å¦‚æœæœ‰åŒ¹é…çš„
                if mask.any():
                    # è¿™æ˜¯ä¸€ä¸ªè¾ƒå¤æ‚çš„æ˜ å°„ï¼Œä¸ºå®‰å…¨èµ·è§è¿˜æ˜¯ç”¨ map æˆ–è€… applyï¼Œä½†åªé’ˆå¯¹ mask éƒ¨åˆ†
                    def apply_match(name):
                        return master_dict.get(name, {})
                    
                    matched_info = df_curr.loc[mask, t_name].apply(apply_match)
                    
                    # æ‰¹é‡å›å¡«
                    # æ³¨æ„ï¼šå°† dict å±•å¼€å›å¡«å¯èƒ½è¾ƒæ…¢ï¼Œè¿™é‡Œç”¨é€åˆ—èµ‹å€¼
                    df_curr.loc[mask, 'æ ‡å‡†ç¼–ç '] = matched_info.apply(lambda x: x.get(MASTER_COL_CODE))
                    df_curr.loc[mask, 'æ ‡å‡†åç§°'] = df_curr.loc[mask, t_name] # æ—¢ç„¶å…¨å­—åŒ¹é…ï¼Œåå­—å°±æ˜¯ key
                    df_curr.loc[mask, 'æ ‡å‡†çœä»½'] = matched_info.apply(lambda x: x.get(MASTER_COL_PROV))
                    df_curr.loc[mask, 'æ ‡å‡†åŸå¸‚'] = matched_info.apply(lambda x: x.get(MASTER_COL_CITY))
                    df_curr.loc[mask, 'åŒ¹é…çŠ¶æ€'] = 'å…¨å­—åŒ¹é…'
                    df_curr.loc[mask, 'ç½®ä¿¡åº¦'] = 1.0
                
                st.session_state.df_result = df_curr
                st.rerun()

        if not st.session_state.processing:
            if st.button("ğŸ§  AI æ·±åº¦åŒ¹é… (5è·¯å¹¶å‘)", type="primary", use_container_width=True):
                if not clients:
                    st.error("æœªé…ç½® API Key")
                else:
                    st.session_state.processing = True
                    st.session_state.stop_signal = False
                    st.rerun()
        else:
            if st.button("ğŸ›‘ æš‚åœ", type="secondary", use_container_width=True):
                st.session_state.stop_signal = True
                st.session_state.processing = False
                st.rerun()

    with col_status:
        progress_bar = st.progress(0)
        status_text = st.empty()
        table_placeholder = st.empty()
        
        # åˆå§‹æ˜¾ç¤º
        table_placeholder.dataframe(
            df_curr, 
            use_container_width=True, 
            column_order=['åŒ¹é…çŠ¶æ€', 'ç½®ä¿¡åº¦', 'åŒ¹é…åŸå› ', col_map['target_name'], 'æ ‡å‡†åç§°'],
            height=300
        )
        
        if st.session_state.processing:
            pending_indices = df_curr[df_curr['åŒ¹é…çŠ¶æ€'] == 'å¾…å¤„ç†'].index.tolist()
            
            if not pending_indices:
                st.session_state.processing = False
                st.success("å…¨éƒ¨å®Œæˆ")
                st.rerun()
            
            # --- å¹¶å‘é€»è¾‘ä¼˜åŒ– ---
            # 1. é™åˆ¶å¹¶å‘æ•°
            MAX_WORKERS = min(len(clients) * 2, 8) # ç¨å¾®æ¿€è¿›ä¸€ç‚¹ï¼Œå³ä½¿Keyå°‘ï¼ŒIOç­‰å¾…æ—¶ä¹Ÿå¯ä»¥åˆ‡
            if MAX_WORKERS < 1: MAX_WORKERS = 1
            
            completed_in_batch = 0
            total_pending = len(pending_indices)
            
            # 2. æ‰¹é‡æ”¶é›†ç»“æœï¼Œè€Œä¸æ˜¯é€æ¡å†™å› DataFrame
            results_buffer = [] 
            
            status_text.text(f"ğŸš€ æ­£åœ¨åˆå§‹åŒ–çº¿ç¨‹æ±  (å¹¶å‘æ•°: {MAX_WORKERS})...")
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
                future_to_idx = {}
                
                # æäº¤ä»»åŠ¡
                for i, idx in enumerate(pending_indices):
                    if st.session_state.stop_signal: break
                    
                    client = clients[i % len(clients)]
                    row_data = df_curr.loc[idx].to_dict() # åªä¼ é€’ dictï¼Œåˆ‡æ–­ä¸ df çš„å¼•ç”¨
                    
                    # å…³é”®ï¼šä¼ å…¥çš„æ˜¯æ•°æ®çš„æ‹·è´ï¼Œä¸”å‡½æ•°å†…ä¸æ“ä½œ UI
                    future = executor.submit(process_row_job, idx, row_data, df_master, col_map, client)
                    future_to_idx[future] = idx
                
                # å¤„ç†ç»“æœ
                start_time = time.time()
                for future in concurrent.futures.as_completed(future_to_idx):
                    if st.session_state.stop_signal: break
                    
                    try:
                        res = future.result()
                        results_buffer.append(res)
                    except Exception as e:
                        print(f"Error: {e}") # åå°æ‰“å°å³å¯
                    
                    completed_in_batch += 1
                    
                    # 3. UI åˆ·æ–°ç­–ç•¥ï¼šèŠ‚æµ (Throttling)
                    # æ¯å®Œæˆ 1 ä¸ªæ›´æ–°è¿›åº¦æ¡(å¼€é”€å°)ï¼Œæ¯å®Œæˆ 10 ä¸ªæˆ– 10% æ›´æ–°è¡¨æ ¼(å¼€é”€å¤§)
                    progress_val = completed_in_batch / total_pending
                    progress_bar.progress(progress_val)
                    
                    elapsed = time.time() - start_time
                    speed = completed_in_batch / elapsed if elapsed > 0 else 0
                    status_text.markdown(f"**å¤„ç†ä¸­...** | é€Ÿåº¦: {speed:.1f} æ¡/ç§’ | å·²å®Œæˆ: {completed_in_batch}/{total_pending}")
                    
                    # æ‰¹é‡å†™å›ä¸» DataFrame å¹¶åˆ·æ–°è¡¨æ ¼
                    # è¿™é‡Œçš„æ•°å­— 10 å¯ä»¥æ ¹æ®å®é™…ä½“éªŒè°ƒæ•´ï¼Œè¶Šå¤§è¶Šæµç•…ï¼Œä½†å®æ—¶åé¦ˆè¶Šæ…¢
                    if len(results_buffer) >= 10:
                        for res in results_buffer:
                            idx_res = res['idx']
                            for k, v in res.items():
                                if k != 'idx':
                                    df_curr.at[idx_res, k] = v
                        results_buffer = [] # æ¸…ç©ºç¼“å†²
                        
                        # æ›´æ–°è¡¨æ ¼é¢„è§ˆ
                        table_placeholder.dataframe(
                            df_curr, 
                            use_container_width=True, 
                            column_order=['åŒ¹é…çŠ¶æ€', 'ç½®ä¿¡åº¦', 'åŒ¹é…åŸå› ', col_map['target_name'], 'æ ‡å‡†åç§°'],
                            height=300
                        )

                # å¾ªç¯ç»“æŸï¼Œå¤„ç†å‰©ä½™ç¼“å†²
                if results_buffer:
                    for res in results_buffer:
                        idx_res = res['idx']
                        for k, v in res.items():
                            if k != 'idx':
                                df_curr.at[idx_res, k] = v
            
            st.session_state.df_result = df_curr
            st.session_state.processing = False
            st.rerun()


